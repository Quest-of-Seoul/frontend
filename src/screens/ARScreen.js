/**
 * AR Screen - Expo Camera Version
 * Main AR experience with docent interaction
 */

import React, { useState, useEffect } from 'react';
import {
  View,
  StyleSheet,
  TouchableOpacity,
  Text,
  SafeAreaView,
  Alert,
} from 'react-native';
import ARSceneComponent from '../components/ARScene';
import DocentDialog from '../components/DocentDialog';
import { getCurrentUser } from '../utils/supabase';
import { getDocentMessage, getDocentMessageWS, addPoints } from '../api/fastapi';
import { playAudioFromBase64, playAudioFromURL, playAudioChunkStreaming, clearAudioQueue, configureAudioMode, isExpoGo } from '../utils/audio';

const ARScreen = ({ route, navigation }) => {
  const { quest } = route.params || {};
  const [showDialog, setShowDialog] = useState(false);
  const [docentMessage, setDocentMessage] = useState('');
  const [userId, setUserId] = useState(null);
  const [hasConversed, setHasConversed] = useState(false);
  const [isMuted, setIsMuted] = useState(false); // TTS ìŒì†Œê±° ìƒíƒœ (ì „ì²´ í™”ë©´ì—ì„œ ìœ ì§€)

  useEffect(() => {
    // Configure audio mode on mount
    configureAudioMode();

    loadUser();
    if (quest) {
      loadInitialMessage();
    }
  }, [quest]);

  const loadUser = async () => {
    const user = await getCurrentUser();
    if (user) {
      setUserId(user.id);
    }
  };

  const loadInitialMessage = async () => {
    if (!quest) return;

    try {
      const user = await getCurrentUser();
      if (!user) return;

      const useExpoGo = isExpoGo();

      if (useExpoGo) {
        // Expo Go: Use REST API with URL
        console.log(`ğŸ“¡ Loading initial message via REST API (Expo Go) - Text only (no TTS for initial)`);

        const response = await getDocentMessage(user.id, quest.name, null, 'ko', false);
        setDocentMessage(response.message);
        setShowDialog(true);
        setHasConversed(true);

        // Initial message: no audio playback (text only)
        console.log('ğŸ“ Initial message loaded - text only (no TTS)');
      } else {
        // Standalone: Use WebSocket streaming
        console.log(`ğŸ”Œ Loading initial message via WebSocket - Text only (no TTS for initial)`);

        const response = await getDocentMessageWS(
          user.id,
          quest.name,
          null,
          'ko',
          // Text received callback
          (data) => {
            console.log('ğŸ“¨ Initial message received');
            setDocentMessage(data.message);
            setShowDialog(true);
            setHasConversed(true);
          },
          // Audio chunk received callback - not used for initial message
          null,
          false  // enable_tts = false for initial message
        );

        console.log('âœ… Initial message WebSocket streaming complete');
      }
    } catch (error) {
      console.error('Error loading initial message:', error);
    }
  };

  const handleCameraReady = () => {
    console.log('Camera ready');
  };

  const handleMessageReceived = (response) => {
    setDocentMessage(response.message);
    setHasConversed(true); // Mark that user has conversed with docent
    // Audio is already handled in DocentDialog
  };

  const toggleDialog = () => {
    // Check if quest exists
    if (!quest) {
      Alert.alert(
        'ì•ˆë‚´',
        'í€˜ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì§„í–‰í•´ì£¼ì„¸ìš”!',
        [
          {
            text: 'í™•ì¸',
            onPress: () => navigation.navigate('Quest'),
          },
        ]
      );
      return;
    }

    setShowDialog(!showDialog);
  };

  const handleExploreComplete = async () => {
    // Check if quest exists
    if (!quest) {
      Alert.alert(
        'ì•ˆë‚´',
        'í€˜ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì§„í–‰í•´ì£¼ì„¸ìš”!',
        [
          {
            text: 'í™•ì¸',
            onPress: () => navigation.navigate('Quest'),
          },
        ]
      );
      return;
    }

    // Check if user has conversed with docent first
    if (!hasConversed) {
      Alert.alert('ì•ˆë‚´', 'ë„ìŠ¨íŠ¸ì™€ ëŒ€í™”ë¥¼ ë¨¼ì € ì§„í–‰í•´ì£¼ì„¸ìš”');
      return;
    }

    if (!userId) {
      Alert.alert('ì˜¤ë¥˜', 'ì‚¬ìš©ì ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    try {
      // Add points to user
      const points = quest.reward_point || 100; // Use quest's reward_point or default 100
      const result = await addPoints(userId, points, `${quest.name} íƒí—˜ ì™„ë£Œ`);

      console.log('âœ… Points added successfully:', result);

      Alert.alert(
        'ğŸ‰ íƒí—˜ ì™„ë£Œ!',
        `${quest.name} íƒí—˜ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!\n${points} í¬ì¸íŠ¸ë¥¼ íšë“í–ˆìŠµë‹ˆë‹¤.`,
        [
          {
            text: 'í™•ì¸',
            onPress: () => navigation.goBack(),
          },
        ]
      );
    } catch (error) {
      console.error('âŒ Error completing quest:', error);
      console.error('Error details:', error.response?.data || error.message);
      Alert.alert(
        'ì˜¤ë¥˜',
        `í¬ì¸íŠ¸ ì ë¦½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n${error.response?.data?.detail || error.message}`
      );
    }
  };

  return (
    <SafeAreaView style={styles.container}>
      {/* AR Scene with Camera */}
      <View style={styles.arContainer}>
        <ARSceneComponent
          onCameraReady={handleCameraReady}
          docentMessage={showDialog ? null : docentMessage}
          onExploreComplete={handleExploreComplete}
        />
      </View>

      {/* Control Buttons */}
      <View style={styles.controlsContainer}>
        <TouchableOpacity style={styles.controlButton} onPress={toggleDialog}>
          <Text style={styles.controlButtonText}>
            {showDialog ? 'ğŸ’¬ ëŒ€í™” ë‹«ê¸°' : 'ğŸ’¬ ë„ìŠ¨íŠ¸ì™€ ëŒ€í™”'}
          </Text>
        </TouchableOpacity>

        <TouchableOpacity
          style={[styles.controlButton, styles.backButton]}
          onPress={() => navigation.goBack()}
        >
          <Text style={styles.controlButtonText}>â† ë’¤ë¡œ</Text>
        </TouchableOpacity>
      </View>

      {/* Docent Dialog */}
      {showDialog && userId && quest && (
        <View style={styles.dialogContainer}>
          <DocentDialog
            userId={userId}
            landmark={quest.name}
            onMessageReceived={handleMessageReceived}
            isMuted={isMuted}
            setIsMuted={setIsMuted}
          />
        </View>
      )}
    </SafeAreaView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#000000',
  },
  arContainer: {
    flex: 1,
  },
  controlsContainer: {
    position: 'absolute',
    top: 60,
    left: 20,
    right: 20,
    flexDirection: 'row',
    justifyContent: 'space-between',
  },
  controlButton: {
    backgroundColor: 'rgba(99, 102, 241, 0.9)',
    paddingHorizontal: 20,
    paddingVertical: 12,
    borderRadius: 20,
  },
  backButton: {
    backgroundColor: 'rgba(107, 114, 128, 0.9)',
  },
  controlButtonText: {
    color: '#ffffff',
    fontSize: 16,
    fontWeight: '600',
  },
  dialogContainer: {
    position: 'absolute',
    bottom: 0,
    left: 0,
    right: 0,
    height: '60%',
    backgroundColor: '#ffffff',
    borderTopLeftRadius: 20,
    borderTopRightRadius: 20,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: -4 },
    shadowOpacity: 0.3,
    shadowRadius: 8,
    elevation: 10,
  },
});

export default ARScreen;
